---
title: "Getting Started with PITmodelR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with PITmodelR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  eval = FALSE,
  collapse = TRUE,
  comment = "#>",
  fig.width = 7, fig.height = 4,
  message = TRUE, warning = TRUE
)
```

# Overview

`PITmodelR` streamlines access to [PTAGIS](https://www.ptagis.org/) data through their [API endpoints](api.ptagis.org) and provides helper tools for PIT-tag data workflows, including project discovery, site metadata, tag observations, and survival/migration modeling.

The package does not replace the user's responsibility to ensure the data is used properly and subset to a sample of tags representing their population of interest. Additionally, the modeling tools within will lead to erroneous results if careful thought isn't given at each step and assumptions are violated.

The purpose of this vignette shows how to:
- Install the package
- Request and configure API authentication
- Retrieve project codes and years of available data
- Explore MRR and interrogation site metadata
- Download mark-recapture-recovery (MRR) files and interrogation site PIT-tag data
- Retrieve tag event histories

> **Note:** Most of the code chunks within this vignette make HTTP requests, many requiring an API-key, as such, examples are set to `eval = FALSE` to keep this vignette runnable on CRAN and all machines. Try them locally after setting up your own API key.

---

# Set-up

Install the `PITmodelR` package from GitHub using the `install_github()` function from the package `remotes`.

```{r}
# install.packages("remotes")
remotes::install_github("ryankinzer/PITmodelR")
```

Similar to all R package a user must load the package into the R session environment before the functions will operate. Load the package using `library()`.

```{r}
library(PITmodelR)
```


Many of the functions require an API key to successfully reach the PTAGIS endpoints. Request the key from PTAGIS staff at this [link](https://www.ptagis.org/Contact). Pass the key directly to functions as a character string using the argument "PTAGIS_API_KEY" or set it once as a session environment variable.

```{r}
# save the api key in the session environment
Sys.setenv(PTAGIS_API_KEY = "YOUR-PTAGIS-API-KEY")
```

Another option is to add the variable `PTAGIS_API_KEY` permanently to your `~/.Renviron` file for persistent use. The steps necessary to complete this action are not included in this tutorial but can easily be found online.

---

# Project Data

PTAGIS files are organized into projects with a three character code. In the past, these project codes were called "Coordinator IDs". A project code is appended to the name of every data file uploaded to PTAGIS. The function `get_project_codes()` returns a vector of all project codes that have data associated with them in PTAGIS.

```{r}
codes <- get_project_codes()
```

Package users may need to check the number of years a specific project has submitted PIT-tag data. This task is completed with `get_project_years()`. The function will return a vector of integers. 

```{r eval=FALSE}
yrs <- get_project_years(code = "CDR")
```

Individual mark-recapture-recovery (MRR) files submitted for a given project and year are obtained with the function `get_mrr_files()`. A small tibble is returned containing metadata about the file uploads. 

```{r eval=FALSE}
files <- get_mrr_files(code = "CDR", year = 2024)
```

After we know which files are available we can then download all uploaded data submitted with the file using `get_file_data()`. The function returns a list with four objects; session, events, session_pdv_fields, and detail_pdv_fields. The list can then be collapsed into a simple data frame using `flatten_mrr_file()` for easier manipulation. 

```{r eval=FALSE}
mrr_file <- get_file_data(files$name[1])
mrr_file$session
mrr_file$events
mrr_file$session_pdv_fields
mrr_file$detail_pdv_fields

df <- flatten_mrr_file(mrr_file)
```
Or, you can download data from multiple MRR files in a single step using the batch function `get_batch_file_data()`. Because uploaded MRR files may not have standardized PDV fields, the function also contains arguments for how the output is returned based on label consistency. The function returns a list with three objects: "files", "combined", and "issues". The "files" object is a nested list with individual objects for each file name supplied to the function. The second object, "combined", is a single data frame with the data flattened across all the files. The final object, "issues", displays discrepancies between user defined field labels (SPDV and PDV).

> **Note:** User defined fields may contain dates, numbers, or character strings, as such, all data in those fields are returned as a character string. Additional data formatting may be necessary if user defined fields require a specific format.

```{r eval=FALSE, message=FALSE}
# get all of CDR file names with 'SRT' at the end
filenames <- grep("SCT\\.xml$", files$name, value = TRUE)

# Batch workflow:
all_data <- get_batch_file_data(
  filenames,
  check_labels = "warn",         # checks if user defined fields have the same labels, can use "error" to stop on mismatches
  keep_code_cols = FALSE,         # should we keep PDV/SPDV code columns and the user defined labels
  label_conflict = "suffix",     # behavior for file label column collisions
  use_codes_on_conflict = TRUE   # prefer consistent code columns across files
)

# list of all individual files
names(all_data$files)

# look at data for a single file
all_data$files$`CDR-2024-183-SCT.xml`

# combined session and event data into a single dataset
df <- all_data$combined

# label mismatch issues
all_data$issues
```
---
# Survival Studies

Survival studies begin with a list of tags that represent the population of interest and that will later be recaptured or observed. The above functions allow us to download all the data associated with MRR files (in this case a mark or tagging files) uploaded to PTAGIS. To create a list of tags suitable for a survival study, we first need to subset the MRR data and filter for tags that best represent our group of interest. This can easily be completed with functions from the `tidyverse` packages.


## Mark List

```{r}
library(tidyverse)

mark_group <- df %>%
  filter(species_run_rear_type == '12W',
         migration_year == 2025,
         between(release_date, ymd(20240901), ymd(20241231)),
         release_site == 'SECTRP',
         pittag != "..........",
         !grepl('RE', text_comments),
         !grepl('Y', conditional_comments)
  )

# check for unique tags
n_distinct(mark_group$pittag)
```

---

## Pit-Tag Histories

After getting the list of tags we then need to gather all observations or recaptures after the fishes' initial release. The function `get_tag_history()` will download the complete tag history for a single specified tag.

```{r eval=FALSE}
pittag <- mark_group$pittag[1]
# only gives a summary of detections at each site......we need to get all detections by antenna/coil
tag_history <- get_tag_history(tag_code = pittag)
```

While the function `get_batch_tag_histories()` will download detections for a list of tag codes.

```{r eval=FALSE}
pittags <- mark_group$pittag
tag_history <- get_batch_tag_histories(tag_codes = pittags)
```

## Recapture Observations

Before fitting a survival model we need to define our survival reaches by identify detection sites of interest. We can start by looking at a table with all the locations the tags were observed.

```{r eval=FALSE}
# summary of event types
table(tag_history$event_type)
# summary of site detections
table(tag_history$site_code)
```

To build my capture history I first need to create a list that designates my reaches of interest and groups site detections to bolster sample sizes. **Caution- take some time to think about mark/recapture and survival modeling assumption violations.** Our reaches of interest include the areas between SECTRP, ZEN, SFG, and Lower Granite Dam. We will group the two juvenile detection sites at Lower Granite Dam (LGR) and all other sites below Lower Granite Dam in order to calculate a more precise detection efficiency at LGR. If we choose to exclude locations from the list, e.g. CWR, they will be automatically dropped from the capture histories. 

```{r eval=FALSE}
# we can define detection sites with a list
locs <- list(
  SECTRP = "SECTRP",
  ZEN    = "ZEN",
  SFG    = "SFG",
  LGR    = c("GRJ","GRS"),
  Down   = c("LMN","MCN","BON", "B2J", "BCC", "GOJ", "ICH", "JDJ", "LMJ", "MCJ", "PD7", "PD8", "PDW", "TWX")
)

res <- build_mark_histories(
  tag_history  = tag_history,
  locs_def     = locs,
  site_col     = "site_code",
  tag_col      = "tag_code",
  time_col     = "event_time",  # optional but helps order ties/revisits
  enforce_order = TRUE,
  keep_unknown  = FALSE
)

ch_data <- res$ch_data      # tag_code, ch
ch_freq <- res$ch_freq      # ch, freq
res$dropped_summary         # any sites removed because they are not listin in `locs`
res$mapping                 # site -> occasion index
```

We can then feed the output of `build_mark_histories()` into a *Cormack-Jolly-Seber* survival model. To fit the model we need to have first installed the R package `marked`. 

```{r eval=TRUE}
# Fit CJS model
#install.packages('marked')

fit <- fit_marked_cjs(res$ch_data,
                      phi_formula = ~ time,
                      p_formula   = ~ time,
                      conf_level  = 0.95)

# Peek tables
head(fit$phi)
head(fit$p)

# Show plots
if (inherits(fit$plots$phi, "ggplot")) {
  print(fit$plots$phi)
  print(fit$plots$p)
} else if (is.function(fit$plots$phi)) {
  fit$plots$phi()  # base plot
  fit$plots$p()
}

# Full model summary if needed
summary(fit$model)

fit$cum_phi         # cumulative survival with CIs
fit$covariance_mode # "full" if covariance used, otherwise "independence_fallback"

# Plot
if (inherits(fit$plots$cum_phi, "ggplot")) {
  print(fit$plots$cum_phi)
} else {
  fit$plots$cum_phi()
}

res$mapping

```


```{r eval=TRUE}
timing <- summarize_arrival_travel(
  tag_history,
  locs_def = locs,
  site_col = "site_code",
  tag_col  = "tag_code",
  time_col = "event_date",
  tz = "UTC",
  keep_unknown = FALSE
)

# Inspect tables
head(timing$arrivals_long)
head(timing$travel_long)
timing$occasion_summary
timing$leg_summary
timing$dropped_summary  # sites filtered out

# Plots
plots <- plot_arrival_travel(timing)
if (inherits(plots$arrival_ecdf, "ggplot")) {
  print(plots$arrival_ecdf)
  print(plots$travel_time)
} else {
  plots$arrival_ecdf()  # base fallback
  plots$travel_time()
}
```

---

# Interrogation Sites

## List interrogation sites (metadata)

```{r}
obs_sites <- get_interrogation_sites()
#obs_sites <- get_interrogation_sites(active_only = FALSE)
```

## Get metadata for a single site

```{r}
get_site_metadata(obs_sites$siteCode[1])
```


## Get site observations (with auto-pagination)

This section is currently non-functional.

```{r}
obs <- get_site_observations(site_code = "COC", year = 2023)
obs_page1 <- get_site_observations(site_code = "COC", year = 2023, page = 1, page_size = 1000, all_pages = FALSE)
obs_small <- get_site_observations(
  site_code = "COC", year = 2023,
  fields = c("event_time", "tag_code", "antenna", "site_code")
)
```

---

# Error handling & best practices

- Functions use a resilient HTTP layer with retries and helpful error messages.
- When nothing is returned, functions **warn** (instead of stopping) and return an empty tibble or vector.
- Common transformations:
  - Names normalized to `snake_case`
  - Returns standardized to **tibble** for downstream use
- For long queries or production code, consider:
  - Caching responses (e.g., `memoise` package)
  - Rate limiting / backoff on large downloads
  - Filtering by time windows when available

---

# Session info

```{r}
sessionInfo()
```

---

# Appendix: Troubleshooting

- **HTTP 4xx** errors: verify your API key, parameters, and endpoint paths.
- **Empty results**: confirm `site_code`, `tag_code`, date/year filters, and that the site/tag actually has records.
- **Name mismatches**: after `snake_case` normalization, field names may differ slightly from raw API (e.g., `SiteCode` â†’ `site_code`).
