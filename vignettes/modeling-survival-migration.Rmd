---
title: "Modeling Survival and Migration Timing with PITmodelR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Modeling Survival and Migration Timing with PITmodelR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7, fig.height = 4,
  message = TRUE, warning = TRUE
)
```

# Overview

This vignette demonstrates end-to-end workflows for **juvenile survival** and **migration timing** modeling using `PITmodelR`. The examples show how to:

1. Download and tidy PTAGIS detections
2. Build detection histories suitable for survival models
3. Fit simple CJS-style survival models
4. Estimate migration timing metrics (quantiles, cumulative passage)
5. Visualize results and export summaries

> **Note**  
> To keep the vignette portable (e.g., CRAN checks), code chunks that require network access or substantial compute are set to `eval = FALSE`. Run them locally after setting up your PTAGIS API key.

---

# Prerequisites

```{r eval=FALSE}
# Install PITmodelR (development)
# install.packages("remotes")
remotes::install_github("yourusername/PITmodelR")

# Optional: modeling packages you may use internally or downstream
install.packages(c("survival", "mgcv", "ggplot2", "dplyr", "tidyr"))
```

Load libraries:

```{r}
library(PITmodelR)
```

Set the API key once per session (or store in `~/.Renviron`):

```{r eval=FALSE}
Sys.setenv(PTAGIS_API_KEY = "YOUR-PTAGIS-API-KEY")
```

---

# 1) Retrieve and Inspect Data

We will illustrate a typical juvenile passage workflow at `LGR` for a single year.

```{r eval=FALSE}
# Example parameters
site   <- "LGR"
year   <- 2023

# Pull site observations (auto-paginates by default)
obs <- get_site_observations(site_code = site, year = year)
dplyr::glimpse(obs)
```

If you already have a list of PIT tags of interest, you can pull event histories individually and bind them:

```{r eval=FALSE}
tags <- c("384.1B79726A98", "384.1A2B3C4D5E", "3D9.1F00ABCD123")
hist_list <- lapply(tags, function(tc) get_tag_history(tag_code = tc))
hist <- dplyr::bind_rows(hist_list, .id = "tag_index")
dplyr::glimpse(hist)
```

---

# 2) Build Detection Histories

Transform raw observations into **encounter histories** or **capture histories** that model functions expect. The exact columns depend on your modeling approach; here is a generic pattern.

```{r eval=FALSE}
# Hypothetical helper: convert events to detection histories by route/reach
# (Replace with your package's real helper names when implemented)
histories <- build_detection_histories(
  observations = obs,
  route_sites  = c("LGR","LGS","LMN","MCN"),  # example route
  tag_col      = "tag_code",
  time_col     = "event_time",
  site_col     = "site_code"
)

# Inspect the detection matrix / long-form representation
head(histories$long)
head(histories$wide)
```

**Notes**
- If you model **reach-level survival**, ensure each reach is clearly defined (e.g., LGR→LGS, LGS→LMN, LMN→MCN).
- If you use time-since-release or DOY, compute those covariates here.

```{r eval=FALSE}
# Add covariates for modeling (examples)
histories$long <- histories$long |>
  dplyr::mutate(
    doy = as.integer(strftime(event_time, format = "%j")),
    hour = as.integer(strftime(event_time, format = "%H"))
  )
```

---

# 3) Fit Survival Models (CJS-style)

Below are two common modeling approaches you might support: a **simple CJS** and an extension with **covariates**. Replace function names with your package's exported modeling functions when available (e.g., `fit_survival()`).

```{r eval=FALSE}
# Minimal CJS-style survival by reach
cjs_fit <- fit_survival(
  histories = histories,
  model    = "cjs",                # or "multistate" if supported later
  formula  = ~ 1                   # constant survival/detection
)

summary(cjs_fit)
plot(cjs_fit)  # if you provide an S3 plot() method
```

Add **covariates** (e.g., DOY, flow) on survival (`phi`) or detection (`p`).

```{r eval=FALSE}
cjs_fit_cov <- fit_survival(
  histories = histories,
  model     = "cjs",
  formula   = list(
    phi = ~ doy,   # survival ~ day of year
    p   = ~ 1      # constant detection probability
  )
)

summary(cjs_fit_cov)
```

Extract and format **reach-level survival** estimates with confidence intervals:

```{r eval=FALSE}
surv_tbl <- summarize_survival(cjs_fit_cov, level = 0.95)
print(surv_tbl)

# Optional: export
# write.csv(surv_tbl, "reach_survival.csv", row.names = FALSE)
```

---

# 4) Migration Timing

Quantify **migration timing** via arrival distributions, passage quantiles, and cumulative passage curves.

```{r eval=FALSE}
# Estimate timing with quantiles (e.g., 10%, 50%, 90% passage)
timing <- fit_timing(
  observations = obs,
  time_col     = "event_time",
  by          = "day",        # aggregate by day
  quantiles   = c(0.1, 0.5, 0.9)
)

timing
```

You may also support a **smooth arrival curve** using a GAM for daily counts.

```{r eval=FALSE}
timing_gam <- fit_timing(
  observations = obs,
  method       = "gam",
  time_col     = "event_time",
  by           = "day"
)

summary(timing_gam$model)  # if you return the fitted mgcv object
```

Plot cumulative passage / arrival distributions:

```{r eval=FALSE}
# Simple passage curve
pass <- passage_curve(timing)
plot_timing(pass)

# If your plot functions support additional arguments:
plot_timing(pass, add_points = TRUE, ci = TRUE)
```

---

# 5) Visualize and Report

Produce figures suitable for reports and manuscripts.

```{r eval=FALSE}
# Survival by reach with CIs
plot_survival(surv_tbl)  # e.g., bar/point-range by reach

# Arrival / cumulative passage
plot_timing(timing)

# Save figures
# ggplot2::ggsave("survival_by_reach.png", width = 7, height = 4, dpi = 300)
# ggplot2::ggsave("cumulative_passage.png", width = 7, height = 4, dpi = 300)
```

---

# 6) Reproducibility & Export

```{r eval=FALSE}
# Save key artifacts
saveRDS(cjs_fit_cov, file = "cjs_fit_cov.rds")
saveRDS(timing,     file = "timing_quantiles.rds")

# Export tidy tables
# readr::write_csv(surv_tbl, "reach_survival.csv")
# readr::write_csv(timing,   "timing_quantiles.csv")
```

---

# 7) Putting It Together: End-to-End Example (Pseudo)

```{r eval=FALSE}
site   <- "LGR"
year   <- 2023

obs <- get_site_observations(site_code = site, year = year)

histories <- build_detection_histories(
  observations = obs,
  route_sites  = c("LGR","LGS","LMN","MCN"),
  tag_col      = "tag_code",
  time_col     = "event_time",
  site_col     = "site_code"
)

cjs_fit <- fit_survival(
  histories = histories,
  model     = "cjs",
  formula   = list(phi = ~ doy, p = ~ 1)
)

surv_tbl <- summarize_survival(cjs_fit, level = 0.95)

timing <- fit_timing(
  observations = obs,
  time_col     = "event_time",
  by           = "day",
  quantiles    = c(0.1, 0.5, 0.9)
)

pass <- passage_curve(timing)

# Visuals
plot_survival(surv_tbl)
plot_timing(pass)
```

---

# Session info

```{r}
sessionInfo()
```

---

# Notes

- Function names used here (`build_detection_histories()`, `fit_survival()`, `summarize_survival()`, `fit_timing()`, `passage_curve()`, `plot_survival()`, `plot_timing()`) are **placeholders** for your package's exported API. Adjust to match the final names.
- Ensure vignettes mark long-running or network-dependent chunks with `eval = FALSE`.
- Consider adding small synthetic datasets in `inst/extdata/` for fully runnable examples without PTAGIS access.
