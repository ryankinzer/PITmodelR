---
title: "Modeling Survival and Migration Timing with PITmodelR"
author: Ryan Kinzer
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Modeling Survival and Migration Timing with PITmodelR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r echo = FALSE, message = FALSE, warning = FALSE, results = "hide"}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = TRUE,
  message = TRUE, 
  fig.width = 7, 
  fig.height = 4,
  comment = "#>"
)

```

```{r setup, include = FALSE}
# required_pkgs <- c(
#   "dplyr",
#   "tidyr",
#   "ggplot2",
#   "lubridate",
#   "marked"
# )
# 
# missing <- required_pkgs[!vapply(required_pkgs, requireNamespace, logical(1), quietly = TRUE)]
# 
# if (length(missing)) {
#   stop(
#     "The following packages are required to build this vignette but are not installed: ",
#     paste(missing, collapse = ", "),
#     call. = FALSE
#   )
# }

library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(marked)
```

# Overview

This vignette demonstrates end-to-end workflows for **juvenile survival** and **migration timing** modeling using `PITmodelR`. The examples show how to:

1. Download and tidy PTAGIS detections,
2. Build detection histories suitable for survival models,
3. Fit simple CJS-style survival models,
4. Estimate migration timing metrics (quantiles, cumulative passage), and
5. Visualize results and export summaries.

> **Note:** To keep the vignette portable (e.g., CRAN checks), code chunks that require network access or substantial compute are set to `eval = FALSE`. Run them locally after setting up your PTAGIS API key.

---

# Prerequisites

This vignette will require the packages `marked` and `PITmodelR` (among others) to function correctly. Please install them before moving forward. You can use `install_packages()` for [available CRAN packages](https://cran.r-project.org/web/packages/available_packages_by_name.html) and `remotes::install_github()` for packages on [GitHub](https://github.com/):

```{r eval = FALSE}
# install packages from CRAN
install.packages(c("marked", "dplyr", "tidyr", "ggplot2", "lubridate"))

# install PITmodelR from GitHub
remotes::install_github("ryankinzer/PITmodelR")

```

Once installed, load these packages into your library:

```{r eval = TRUE}
# load PITmodelR into library
library(PITmodelR)
```

Many functions within the package require a PTAGIS API key to function. Request the key from PTAGIS staff at this [link](https://www.ptagis.org/Contact). The key can be set once per session following:

```{r eval = FALSE}
your_api_key = "YOUR-PTAGIS-API-KEY"
Sys.setenv(PTAGIS_API_KEY = your_api_key)
```

Another option is to add `PTAGIS_API_KEY` permanently to your `~/.Renviron` file for persistent use. The steps to do this are not covered in this tutorial. Remember to **keep your API key private** and do not share it publicly.

---

# 1) Retrieve and Inspect Data

We will illustrate a typical juvenile passage workflow at `LGR` for a single year.

```{r eval = FALSE}
# example parameters for get_site_observations()
site   <- "IR3" # consider changing, GRS is a big download
year   <- 2024

# retrieve site observations (auto-paginates by default)
obs <- get_site_observations(site_code = site, year = year)
dplyr::glimpse(obs)
```

If you already have a list of PIT tags of interest, you can pull event histories individually and bind them:

```{r eval = FALSE}
tags <- c("384.1B79726A98", "384.1A2B3C4D5E", "3D9.1F00ABCD123")
hist_list <- lapply(tags, function(tc) get_tag_history(tag_code = tc))
hist <- dplyr::bind_rows(hist_list, .id = "tag_index")
dplyr::glimpse(hist)
```

---

# 2) Build Detection Histories

Transform raw observations into **encounter histories** or **capture histories** that model functions expect. The exact columns depend on your modeling approach; here is a generic pattern.

```{r eval=FALSE}
# Hypothetical helper: convert events to detection histories by route/reach
# (Replace with your package's real helper names when implemented)
histories <- build_detection_histories(
  observations = obs,
  route_sites  = c("LGR","LGS","LMN","MCN"),  # example route
  tag_col      = "tag_code",
  time_col     = "event_time",
  site_col     = "site_code"
)

# Inspect the detection matrix / long-form representation
head(histories$long)
head(histories$wide)
```

**Notes**
- If you model **reach-level survival**, ensure each reach is clearly defined (e.g., LGR→LGS, LGS→LMN, LMN→MCN).
- If you use time-since-release or DOY, compute those covariates here.

```{r eval=FALSE}
# Add covariates for modeling (examples)
histories$long <- histories$long |>
  dplyr::mutate(
    doy = as.integer(strftime(event_time, format = "%j")),
    hour = as.integer(strftime(event_time, format = "%H"))
  )
```

---

# 3) Fit Survival Models (CJS-style)

Below are two common modeling approaches you might support: a **simple CJS** and an extension with **covariates**. Replace function names with your package's exported modeling functions when available (e.g., `fit_survival()`).

```{r eval=FALSE}
# Minimal CJS-style survival by reach
cjs_fit <- fit_survival(
  histories = histories,
  model    = "cjs",                # or "multistate" if supported later
  formula  = ~ 1                   # constant survival/detection
)

summary(cjs_fit)
plot(cjs_fit)  # if you provide an S3 plot() method
```

Add **covariates** (e.g., DOY, flow) on survival (`phi`) or detection (`p`).

```{r eval=FALSE}
cjs_fit_cov <- fit_survival(
  histories = histories,
  model     = "cjs",
  formula   = list(
    phi = ~ doy,   # survival ~ day of year
    p   = ~ 1      # constant detection probability
  )
)

summary(cjs_fit_cov)
```

Extract and format **reach-level survival** estimates with confidence intervals:

```{r eval=FALSE}
surv_tbl <- summarize_survival(cjs_fit_cov, level = 0.95)
print(surv_tbl)

# Optional: export
# write.csv(surv_tbl, "reach_survival.csv", row.names = FALSE)
```

---

# 4) Migration Timing

Quantify **migration timing** via arrival distributions, passage quantiles, and cumulative passage curves.

```{r eval=FALSE}
# Estimate timing with quantiles (e.g., 10%, 50%, 90% passage)
timing <- fit_timing(
  observations = obs,
  time_col     = "event_time",
  by          = "day",        # aggregate by day
  quantiles   = c(0.1, 0.5, 0.9)
)

timing
```

You may also support a **smooth arrival curve** using a GAM for daily counts.

```{r eval=FALSE}
timing_gam <- fit_timing(
  observations = obs,
  method       = "gam",
  time_col     = "event_time",
  by           = "day"
)

summary(timing_gam$model)  # if you return the fitted mgcv object
```

Plot cumulative passage / arrival distributions:

```{r eval=FALSE}
# Simple passage curve
pass <- passage_curve(timing)
plot_timing(pass)

# If your plot functions support additional arguments:
plot_timing(pass, add_points = TRUE, ci = TRUE)
```

---

# 5) Visualize and Report

Produce figures suitable for reports and manuscripts.

```{r eval=FALSE}
# Survival by reach with CIs
plot_survival(surv_tbl)  # e.g., bar/point-range by reach

# Arrival / cumulative passage
plot_timing(timing)

# Save figures
# ggplot2::ggsave("survival_by_reach.png", width = 7, height = 4, dpi = 300)
# ggplot2::ggsave("cumulative_passage.png", width = 7, height = 4, dpi = 300)
```

---

# 6) Reproducibility & Export

```{r eval=FALSE}
# Save key artifacts
saveRDS(cjs_fit_cov, file = "cjs_fit_cov.rds")
saveRDS(timing,     file = "timing_quantiles.rds")

# Export tidy tables
# readr::write_csv(surv_tbl, "reach_survival.csv")
# readr::write_csv(timing,   "timing_quantiles.csv")
```

---

# 7) Putting It Together: End-to-End Example (Pseudo)

```{r eval=FALSE}
site   <- "LGR"
year   <- 2023

obs <- get_site_observations(site_code = site, year = year)

histories <- build_detection_histories(
  observations = obs,
  route_sites  = c("LGR","LGS","LMN","MCN"),
  tag_col      = "tag_code",
  time_col     = "event_time",
  site_col     = "site_code"
)

cjs_fit <- fit_survival(
  histories = histories,
  model     = "cjs",
  formula   = list(phi = ~ doy, p = ~ 1)
)

surv_tbl <- summarize_survival(cjs_fit, level = 0.95)

timing <- fit_timing(
  observations = obs,
  time_col     = "event_time",
  by           = "day",
  quantiles    = c(0.1, 0.5, 0.9)
)

pass <- passage_curve(timing)

# Visuals
plot_survival(surv_tbl)
plot_timing(pass)
```

---

# Session info

```{r}
sessionInfo()
```

---

# Notes

- Function names used here (`build_detection_histories()`, `fit_survival()`, `summarize_survival()`, `fit_timing()`, `passage_curve()`, `plot_survival()`, `plot_timing()`) are **placeholders** for your package's exported API. Adjust to match the final names.
- Ensure vignettes mark long-running or network-dependent chunks with `eval = FALSE`.
- Consider adding small synthetic datasets in `inst/extdata/` for fully runnable examples without PTAGIS access.

```{r eval=FALSE}
proc <- process.data(res$ch_data, model = "CJS")
ddl  <- make.design.data(proc)

Phi.time <- list(formula = ~ time)
p.time   <- list(formula = ~ time)

mod <- crm(proc, ddl, model.parameters = list(Phi = Phi.time, p = p.time))
summary(mod)

mod$results
mod$results$reals$Phi

est_preds = predict(mod) |>
      map(.f = as_tibble)
```


```{r eval = F}

library(PITmodelR)

your_api_key = "YOUR-PTAGIS-API-KEY"
Sys.setenv(PTAGIS_API_KEY = your_api_key)

files <- get_mrr_files(code = "CSS", year = 2025)

# get all of the CSS file names that end in a number
filenames <- grep("[0-9]{3}\\.xml$", files$name, value = TRUE)

# Batch workflow:
all_data <- get_batch_file_data(
  filenames,
  check_labels = "warn",         # checks if user defined fields have the same labels, can use "error" to stop on mismatches
  keep_code_cols = FALSE,         # should we keep PDV/SPDV code columns and the user defined labels
  label_conflict = "suffix",     # behavior for file label column collisions
  use_codes_on_conflict = TRUE   # prefer consistent code columns across files
)

# list of all individual files
names(all_data$files)

# look at data for a single file
all_data$files$`CDR-2024-183-SCT.xml`

# combined session and event data into a single dataset
df <- all_data$combined

# label mismatch issues
all_data$issues

mark_group <- df |>
  filter(species_run_rear_type == '12W',
         migration_year == 2025,
         between(release_date, ymd(20240901), ymd(20241231)),
         release_site == 'SECTRP',
         pittag != "..........",
         !grepl('RE', text_comments),
         !grepl('Y', conditional_comments)
  )

# check for unique tags
n_distinct(mark_group$pittag)

pittags <- mark_group$pittag
tag_history <- get_batch_tag_histories(tag_codes = pittags)

# summary of event types
table(tag_history$event_type)
# summary of site detections
table(tag_history$site_code)

we can define detection sites with a list
locs <- list(
  SECTRP = "SECTRP",
  ZEN    = "ZEN",
  SFG    = "SFG",
  LGR    = c("GRJ","GRS"),
  Down   = c("LMN","MCN","BON", "B2J", "BCC", "GOJ", "ICH", "JDJ", "LMJ", "MCJ", "PD7", "PD8", "PDW", "TWX")
)

res <- build_mark_histories(
  tag_history  = tag_history,
  locs_def     = locs,
  site_col     = "site_code",
  tag_col      = "tag_code",
  time_col     = "event_time",  # optional but helps order ties/revisits
  enforce_order = TRUE,
  keep_unknown  = FALSE
)

ch_data <- res$ch_data      # tag_code, ch
ch_freq <- res$ch_freq      # ch, freq
res$dropped_summary         # any sites removed because they are not listin in `locs`
res$mapping                 # site -> occasion index


# Fit CJS model
#install.packages('marked')

fit <- fit_marked_cjs(res$ch_data,
                      phi_formula = ~ time,
                      p_formula   = ~ time,
                      conf_level  = 0.95)

# Peek tables
head(fit$phi)
head(fit$p)

# Show plots
if (inherits(fit$plots$phi, "ggplot")) {
  print(fit$plots$phi)
  print(fit$plots$p)
} else if (is.function(fit$plots$phi)) {
  fit$plots$phi()  # base plot
  fit$plots$p()
}

# Full model summary if needed
summary(fit$model)

fit$cum_phi         # cumulative survival with CIs
fit$covariance_mode # "full" if covariance used, otherwise "independence_fallback"

# Plot
if (inherits(fit$plots$cum_phi, "ggplot")) {
  print(fit$plots$cum_phi)
} else {
  fit$plots$cum_phi()
}

res$mapping


timing <- summarize_arrival_travel(
  tag_history,
  locs_def = locs,
  site_col = "site_code",
  tag_col  = "tag_code",
  time_col = "event_date",
  tz = "UTC",
  keep_unknown = FALSE
)

# Inspect tables
head(timing$arrivals_long)
head(timing$travel_long)
timing$occasion_summary
timing$leg_summary
timing$dropped_summary  # sites filtered out

# Plots
plots <- plot_arrival_travel(timing)
if (inherits(plots$arrival_ecdf, "ggplot")) {
  print(plots$arrival_ecdf)
  print(plots$travel_time)
} else {
  plots$arrival_ecdf()  # base fallback
  plots$travel_time()
}

```
